{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Michigan University Sentiment Classification Contest (from Kaggle)\n",
    "https://www.kaggle.com/c/si650winter11\n",
    "\n",
    "This contest was hosted by Michigan university for a course. The data set has senteces extracted from social media and then classified into positive or negative. **The training data contains 7086 sentences, already labeled with 1 (positive sentiment) or 0 (negative sentiment).** The data set also contains unlabled data but for this post, I will ONLY use labelled data.\n",
    "\n",
    "I found this data set interesting for learning purpose.\n",
    "\n",
    "I will divide the dataset into training and testing sets. The sentiment is sorted in the file so will shuffle the input data and then use first 5000 as training and rest as testing dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have downloaded the Training data and stored the content in a file named as **michigan_sentiment.txt**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.  DataSet Preparation\n",
    "Load the data and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_data = pd.read_csv('michigan_sentiment.txt', sep='\\t') # read in a Pandas data frame\n",
    "sentiment_data.columns =['Class', 'Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Review count 6917\n",
      "Columns = ['Class' 'Data']\n",
      "Dimension of sentiment_data is (6917, 2)\n",
      "Number of reviews =6917\n",
      "Dimension =(6917, 2)\n",
      "Sentiment Distribution =1    3942\n",
      "0    2975\n",
      "Name: Class, dtype: int64 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>that's not even an exaggeration ) and at midni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                               Data\n",
       "0      1  this was the first clive cussler i've ever rea...\n",
       "1      1                   i liked the Da Vinci Code a lot.\n",
       "2      1                   i liked the Da Vinci Code a lot.\n",
       "3      1  I liked the Da Vinci Code but it ultimatly did...\n",
       "4      1  that's not even an exaggeration ) and at midni..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_reviews = len(sentiment_data);\n",
    "print(\"Total Review count {}\".format(total_reviews))\n",
    "print('Columns = {}'.format(sentiment_data.columns.values))\n",
    "print('Dimension of sentiment_data is {}'.format(sentiment_data.shape))\n",
    "print('Number of reviews ={}'.format(total_reviews))   # or sentiment_data.shape[0]\n",
    "print('Dimension ={}'.format(sentiment_data.shape))\n",
    "print('Sentiment Distribution ={} '.format(sentiment_data['Class'].value_counts()))\n",
    "sentiment_data.head()\n",
    "#sentiment_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomization/Shuffle Dataframe\n",
    "\n",
    "The data is sorted; so we have positive reviews and then followed by all negative reviews. First of all we need to shuffle the dataset so that the modeling is proper. Also, we are using this labeled data for testing as well so we need to have good mix of positive and negative sentiment in each set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "shuffled_sentiment_data = shuffle(sentiment_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split to reviews/input and labels/output data\n",
    "The *Class* column has labels or output and the *Data* column has reviews or inputs in form of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10f8fbb70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f8fb5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_series = shuffled_sentiment_data['Class']   # pandas\n",
    "inputs_series = shuffled_sentiment_data['Data']\n",
    "\n",
    "# Convert above pandas series into numpy array\n",
    "labels = labels_series.values   \n",
    "inputs = inputs_series.values\n",
    "outputs = labels \n",
    "\n",
    "labels_series.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text\n",
    "\n",
    "Remove special characters and also stop words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "special_chars = re.compile(\"[^A-Za-z]+\")   # Remove end of sentence as well\n",
    "\n",
    "def cleanText(review):\n",
    "    '''\n",
    "    Remove punctuation, numbers and special characters.\n",
    "    Also convert all chars to lower case\n",
    "    '''\n",
    "    review = review.lower() # convert to lower case\n",
    "    return re.sub(special_chars, \" \", review) # remove all non alphabetic chars with space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "\n",
    "def removeStopWords(review):\n",
    "    '''\n",
    "    Remove stop words from the reviews\n",
    "    '''\n",
    "    stops = set(stopwords.words(\"english\"))  # set of stop words\n",
    "    review = review.split()  \n",
    "    words = [w for w in review if not w in stops]\n",
    "    return( \" \".join( words )) # joins the words array back to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through all text and clean them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_inputs = []\n",
    "\n",
    "for val in inputs:\n",
    "    cleaned = cleanText(val)\n",
    "    without_stop_words = removeStopWords(cleaned)\n",
    "    cleaned_inputs.append(without_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6917\n",
      "6917\n",
      "BEFORE: I wanted desperately to love'The Da Vinci Code as a film.\n",
      "AFTER: wanted desperately love da vinci code film\n",
      "---\n",
      "BEFORE: I love The Da Vinci Code...\n",
      "AFTER: love da vinci code\n",
      "---\n",
      "BEFORE: dudeee i LOVED brokeback mountain!!!!\n",
      "AFTER: dudeee loved brokeback mountain\n",
      "---\n",
      "BEFORE: I want to be here because I love Harry Potter, and I really want a place where people take it serious, but it is still so much fun.\n",
      "AFTER: want love harry potter really want place people take serious still much fun\n",
      "---\n",
      "BEFORE: da vinci code was an awesome movie...\n",
      "AFTER: da vinci code awesome movie\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned_inputs))\n",
    "print(len(inputs))\n",
    "\n",
    "for i in range(5):\n",
    "    print('BEFORE: {}'.format(inputs[i]))\n",
    "    print('AFTER: {}'.format(cleaned_inputs[i]))\n",
    "    print('---')\n",
    "    \n",
    "# print(cleaned_inputs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Vocab\n",
    "In ths step we are creating the vocabulary of all the reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "\n",
    "for text in cleaned_inputs:\n",
    "    for word in text.split():\n",
    "        all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 46648\n",
      "Unique words 1993\n"
     ]
    }
   ],
   "source": [
    "unique_words = set(all_words)\n",
    "\n",
    "print('Total words {}'.format(len(all_words)))\n",
    "print('Unique words {}'.format(len(unique_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert words to integers for the unique words\n",
    "\n",
    "Create word to integer mapping (for all unique words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('move', 1), ('w', 2), ('majorly', 3), ('grabs', 4), ('decaying', 5), ('quite', 6), ('offence', 7), ('meganpenworthy', 8), ('patirot', 9), ('oceanwalk', 10), ('strangely', 11), ('despised', 12), ('daniel', 13), ('shows', 14), ('jack', 15), ('hp', 16), ('tomkat', 17), ('jane', 18), ('lore', 19), ('knights', 20), ('afterschool', 21), ('pleased', 22), ('halle', 23), ('simple', 24), ('hips', 25), ('serious', 26), ('forever', 27), ('hugh', 28), ('whenever', 29), ('lot', 30), ('know', 31), ('photography', 32), ('prime', 33), ('mind', 34), ('yuck', 35), ('gonna', 36), ('thank', 37), ('tale', 38), ('bolsters', 39), ('maybe', 40), ('symantec', 41), ('harder', 42), ('wept', 43), ('given', 44), ('played', 45), ('anax', 46), ('images', 47), ('blashpemies', 48), ('mainstream', 49), ('anyways', 50), ('independant', 51), ('depressing', 52), ('irrespective', 53), ('clean', 54), ('queens', 55), ('land', 56), ('gladly', 57), ('able', 58), ('bit', 59), ('haircut', 60), ('lamest', 61), ('atrocious', 62), ('starred', 63), ('felt', 64), ('seems', 65), ('code', 66), ('opened', 67), ('exaggeration', 68), ('eyre', 69), ('madly', 70), ('lousy', 71), ('novels', 72), ('bootlegged', 73), ('judging', 74), ('rowling', 75), ('dash', 76), ('thinking', 77), ('sad', 78), ('leads', 79), ('calling', 80), ('great', 81), ('dungeons', 82), ('nature', 83), ('town', 84), ('setting', 85), ('shitty', 86), ('villains', 87), ('witchcraft', 88), ('consider', 89), ('mountain', 90), ('reply', 91), ('alright', 92), ('tiffani', 93), ('basic', 94), ('yahoo', 95), ('gorgeous', 96), ('mall', 97), ('publicly', 98), ('freak', 99), ('btw', 100), ('omen', 101), ('jones', 102), ('needs', 103), ('returning', 104), ('public', 105), ('facing', 106), ('reaction', 107), ('till', 108), ('hair', 109), ('case', 110), ('religious', 111), ('career', 112), ('oreos', 113), ('mph', 114), ('image', 115), ('witha', 116), ('hooray', 117), ('music', 118), ('illegally', 119), ('monchel', 120), ('hella', 121), ('stupid', 122), ('joining', 123), ('already', 124), ('kinda', 125), ('cobequid', 126), ('cast', 127), ('achieved', 128), ('preview', 129), ('jay', 130), ('donkey', 131), ('stinkin', 132), ('gay', 133), ('abortion', 134), ('author', 135), ('reopened', 136), ('suing', 137), ('hot', 138), ('live', 139), ('excersizing', 140), ('angle', 141), ('police', 142), ('quizzes', 143), ('planned', 144), ('captain', 145), ('blog', 146), ('forget', 147), ('level', 148), ('occasional', 149), ('hahahaha', 150), ('pink', 151), ('acne', 152), ('lately', 153), ('kicked', 154), ('nerd', 155), ('liberal', 156), ('hollywoord', 157), ('love', 158), ('asian', 159), ('tent', 160), ('thick', 161), ('g', 162), ('soooooooo', 163), ('bday', 164), ('lee', 165), ('ca', 166), ('linked', 167), ('personaly', 168), ('groaning', 169), ('musiclove', 170), ('nearly', 171), ('kite', 172), ('important', 173), ('latin', 174), ('draw', 175), ('save', 176), ('plastic', 177), ('wif', 178), ('appeal', 179), ('gettting', 180), ('lesson', 181), ('sorcerer', 182), ('left', 183), ('expected', 184), ('belong', 185), ('started', 186), ('fabricated', 187), ('loose', 188), ('increasing', 189), ('halls', 190), ('liked', 191), ('gn', 192), ('carefully', 193), ('creed', 194), ('compared', 195), ('crappy', 196), ('min', 197), ('away', 198), ('worthless', 199), ('add', 200), ('definately', 201), ('random', 202), ('coloured', 203), ('sale', 204), ('bye', 205), ('never', 206), ('drawn', 207), ('change', 208), ('written', 209), ('dressed', 210), ('daddy', 211), ('th', 212), ('game', 213), ('films', 214), ('libarian', 215), ('discovered', 216), ('dating', 217), ('lil', 218), ('tom', 219), ('vice', 220), ('shell', 221), ('erin', 222), ('unless', 223), ('dumbledor', 224), ('material', 225), ('must', 226), ('settin', 227), ('twilight', 228), ('hanging', 229), ('festivities', 230), ('u', 231), ('drive', 232), ('times', 233), ('phase', 234), ('deciding', 235), ('wait', 236), ('long', 237), ('c', 238), ('allegory', 239), ('award', 240), ('big', 241), ('smoked', 242), ('colfer', 243), ('favorite', 244), ('inappropriate', 245), ('believably', 246), ('idk', 247), ('performance', 248), ('sceneries', 249), ('march', 250), ('clive', 251), ('badness', 252), ('snuck', 253), ('boycotted', 254), ('everytime', 255), ('christian', 256), ('arguments', 257), ('generalized', 258), ('wants', 259), ('low', 260), ('lame', 261), ('fantasy', 262), ('chris', 263), ('usage', 264), ('academy', 265), ('heartbraking', 266), ('someone', 267), ('care', 268), ('miss', 269), ('howard', 270), ('writes', 271), ('understand', 272), ('discuss', 273), ('exciting', 274), ('shadeslayer', 275), ('luv', 276), ('wicked', 277), ('hollywood', 278), ('veil', 279), ('controversy', 280), ('favourite', 281), ('helped', 282), ('silver', 283), ('panting', 284), ('kid', 285), ('major', 286), ('gin', 287), ('queer', 288), ('reading', 289), ('lah', 290), ('updated', 291), ('causing', 292), ('starring', 293), ('exhausted', 294), ('review', 295), ('gavin', 296), ('hat', 297), ('runs', 298), ('iq', 299), ('anyhow', 300), ('cover', 301), ('third', 302), ('interesting', 303), ('chicken', 304), ('loathe', 305), ('madre', 306), ('uh', 307), ('shields', 308), ('scientologist', 309), ('sing', 310), ('axes', 311), ('old', 312), ('tree', 313), ('questions', 314), ('kicking', 315), ('undoubtedly', 316), ('frakking', 317), ('none', 318), ('talking', 319), ('need', 320), ('kids', 321), ('fuck', 322), ('drawing', 323), ('struggle', 324), ('dim', 325), ('tests', 326), ('gives', 327), ('shade', 328), ('suck', 329), ('retarded', 330), ('creature', 331), ('enjoy', 332), ('gossip', 333), ('exelent', 334), ('directed', 335), ('tour', 336), ('invisibility', 337), ('check', 338), ('rachel', 339), ('wrote', 340), ('drowining', 341), ('shameful', 342), ('party', 343), ('enjoying', 344), ('aka', 345), ('bout', 346), ('parents', 347), ('dudeee', 348), ('bought', 349), ('scarf', 350), ('rep', 351), ('rent', 352), ('yuh', 353), ('fade', 354), ('mound', 355), ('gathered', 356), ('clips', 357), ('reads', 358), ('appeals', 359), ('altogether', 360), ('husband', 361), ('shoes', 362), ('ossana', 363), ('spoke', 364), ('bayers', 365), ('primary', 366), ('acting', 367), ('bonkers', 368), ('offense', 369), ('unbelievably', 370), ('rules', 371), ('feel', 372), ('characters', 373), ('unfortunately', 374), ('screens', 375), ('reality', 376), ('dakota', 377), ('blows', 378), ('depp', 379), ('bored', 380), ('let', 381), ('bobbypin', 382), ('corrupting', 383), ('dorks', 384), ('conquering', 385), ('blonds', 386), ('seeking', 387), ('mob', 388), ('whereas', 389), ('beating', 390), ('ignorant', 391), ('vinci', 392), ('see', 393), ('cruise', 394), ('anime', 395), ('make', 396), ('character', 397), ('friend', 398), ('fortress', 399), ('cock', 400), ('briefly', 401), ('christ', 402), ('ever', 403), ('straight', 404), ('personally', 405), ('headmistress', 406), ('fun', 407), ('guts', 408), ('stites', 409), ('sakes', 410), ('encourage', 411), ('scenes', 412), ('audrey', 413), ('watched', 414), ('nothin', 415), ('aching', 416), ('bible', 417), ('microsoft', 418), ('alarm', 419), ('nothing', 420), ('screenplay', 421), ('clearly', 422), ('emotes', 423), ('bringing', 424), ('couple', 425), ('bits', 426), ('give', 427), ('instead', 428), ('middle', 429), ('sixth', 430), ('sooo', 431), ('zen', 432), ('unexpected', 433), ('watch', 434), ('including', 435), ('hill', 436), ('zach', 437), ('club', 438), ('um', 439), ('german', 440), ('looked', 441), ('fell', 442), ('amazes', 443), ('children', 444), ('dan', 445), ('holy', 446), ('huge', 447), ('horses', 448), ('wal', 449), ('egg', 450), ('cuz', 451), ('prize', 452), ('throat', 453), ('hippie', 454), ('sarcastic', 455), ('every', 456), ('wanna', 457), ('trivia', 458), ('woo', 459), ('boys', 460), ('kick', 461), ('fan', 462), ('summer', 463), ('rife', 464), ('catch', 465), ('horridly', 466), ('jill', 467), ('discussing', 468), ('bound', 469), ('voted', 470), ('correct', 471), ('sweeping', 472), ('absolute', 473), ('seem', 474), ('feathers', 475), ('comment', 476), ('cut', 477), ('viewings', 478), ('condemnation', 479), ('rockets', 480), ('due', 481), ('since', 482), ('nc', 483), ('else', 484), ('might', 485), ('midnight', 486), ('stars', 487), ('well', 488), ('themed', 489), ('tonight', 490), ('often', 491), ('runner', 492), ('reservations', 493), ('bunch', 494), ('place', 495), ('quick', 496), ('hahahahahaha', 497), ('gayer', 498), ('leah', 499), ('sis', 500), ('kind', 501), ('blame', 502), ('touching', 503), ('lines', 504), ('hung', 505), ('aaron', 506), ('weird', 507), ('easy', 508), ('admiring', 509), ('posted', 510), ('copy', 511), ('counting', 512), ('looking', 513), ('created', 514), ('awesomeness', 515), ('hooked', 516), ('georgia', 517), ('brazil', 518), ('trousers', 519), ('waited', 520), ('scar', 521), ('tv', 522), ('flat', 523), ('burbank', 524), ('night', 525), ('insurance', 526), ('fowl', 527), ('codes', 528), ('genres', 529), ('dragons', 530), ('discussed', 531), ('versa', 532), ('everything', 533), ('anywhere', 534), ('goin', 535), ('la', 536), ('avatar', 537), ('receive', 538), ('mouth', 539), ('prisoner', 540), ('etc', 541), ('acoustic', 542), ('trece', 543), ('stand', 544), ('lilo', 545), ('ran', 546), ('mi', 547), ('relaxed', 548), ('collection', 549), ('want', 550), ('ticket', 551), ('ennis', 552), ('becuase', 553), ('sounds', 554), ('cant', 555), ('thought', 556), ('according', 557), ('lords', 558), ('theories', 559), ('realized', 560), ('especially', 561), ('deserved', 562), ('gaither', 563), ('everybody', 564), ('geisha', 565), ('kenley', 566), ('historical', 567), ('grips', 568), ('cry', 569), ('iii', 570), ('sense', 571), ('absolutely', 572), ('ripper', 573), ('purchase', 574), ('backward', 575), ('monsters', 576), ('screwed', 577), ('afterwards', 578), ('retarted', 579), ('gym', 580), ('cloak', 581), ('team', 582), ('raises', 583), ('challenge', 584), ('far', 585), ('things', 586), ('disappointed', 587), ('right', 588), ('happened', 589), ('urls', 590), ('vampire', 591), ('magical', 592), ('doors', 593), ('tons', 594), ('community', 595), ('disliked', 596), ('futile', 597), ('romantic', 598), ('fully', 599), ('grown', 600), ('facile', 601), ('kept', 602), ('itz', 603), ('happiness', 604), ('hanks', 605), ('favor', 606), ('dearly', 607), ('beautiful', 608), ('putting', 609), ('final', 610), ('enjoys', 611), ('halfway', 612), ('crafted', 613), ('us', 614), ('scared', 615), ('ang', 616), ('vigor', 617), ('ate', 618), ('yet', 619), ('education', 620), ('time', 621), ('showcasing', 622), ('nans', 623), ('calif', 624), ('stop', 625), ('theme', 626), ('quirky', 627), ('kelse', 628), ('butt', 629), ('goblet', 630), ('quip', 631), ('overcoming', 632), ('update', 633), ('probably', 634), ('rest', 635), ('presented', 636), ('outnumbered', 637), ('fiber', 638), ('freakin', 639), ('indian', 640), ('home', 641), ('confess', 642), ('mtv', 643), ('says', 644), ('aside', 645), ('anyone', 646), ('literature', 647), ('deemed', 648), ('lol', 649), ('baby', 650), ('clit', 651), ('latter', 652), ('generally', 653), ('grow', 654), ('catcher', 655), ('hank', 656), ('jelly', 657), ('unable', 658), ('wotshisface', 659), ('though', 660), ('classes', 661), ('plot', 662), ('mart', 663), ('cars', 664), ('came', 665), ('pm', 666), ('outta', 667), ('picturesque', 668), ('reasons', 669), ('hugged', 670), ('esther', 671), ('ur', 672), ('watson', 673), ('eh', 674), ('sawyer', 675), ('scifi', 676), ('wonderful', 677), ('lin', 678), ('measure', 679), ('tye', 680), ('desperately', 681), ('overexagerated', 682), ('date', 683), ('lost', 684), ('nifty', 685), ('soundtrack', 686), ('generated', 687), ('girl', 688), ('moving', 689), ('teri', 690), ('dictate', 691), ('et', 692), ('planning', 693), ('hahash', 694), ('complex', 695), ('freezing', 696), ('marcia', 697), ('phenomenon', 698), ('signs', 699), ('attempt', 700), ('seymore', 701), ('break', 702), ('mormon', 703), ('edition', 704), ('melandry', 705), ('usually', 706), ('pictures', 707), ('oh', 708), ('homophobic', 709), ('literary', 710), ('kanye', 711), ('starting', 712), ('name', 713), ('p', 714), ('keys', 715), ('pastings', 716), ('comes', 717), ('actually', 718), ('camp', 719), ('unfortunate', 720), ('archive', 721), ('agree', 722), ('denial', 723), ('small', 724), ('fireworks', 725), ('invisible', 726), ('use', 727), ('dont', 728), ('days', 729), ('nd', 730), ('record', 731), ('creatures', 732), ('shout', 733), ('god', 734), ('revise', 735), ('beatles', 736), ('everyone', 737), ('plus', 738), ('ring', 739), ('da', 740), ('without', 741), ('taking', 742), ('cold', 743), ('thirdly', 744), ('worth', 745), ('theatan', 746), ('theres', 747), ('balls', 748), ('gary', 749), ('theater', 750), ('supportive', 751), ('possibly', 752), ('beans', 753), ('storytimes', 754), ('wherever', 755), ('tech', 756), ('france', 757), ('truly', 758), ('holding', 759), ('cannot', 760), ('suncoast', 761), ('writers', 762), ('teevee', 763), ('indicative', 764), ('figure', 765), ('devastate', 766), ('impossible', 767), ('cowan', 768), ('america', 769), ('yes', 770), ('hoffman', 771), ('caribbean', 772), ('general', 773), ('took', 774), ('dragged', 775), ('honest', 776), ('totally', 777), ('experience', 778), ('congrats', 779), ('stitch', 780), ('cheap', 781), ('theaters', 782), ('eating', 783), ('paper', 784), ('dumb', 785), ('riding', 786), ('messiah', 787), ('throw', 788), ('scenario', 789), ('fuckers', 790), ('ones', 791), ('hooker', 792), ('brigid', 793), ('mybutthole', 794), ('nicely', 795), ('goes', 796), ('bond', 797), ('ground', 798), ('transamerica', 799), ('jamie', 800), ('college', 801), ('doubt', 802), ('seriously', 803), ('fix', 804), ('skin', 805), ('hide', 806), ('matter', 807), ('demeantor', 808), ('runaway', 809), ('hand', 810), ('row', 811), ('grey', 812), ('ti', 813), ('van', 814), ('stopped', 815), ('sisters', 816), ('margaritas', 817), ('type', 818), ('truth', 819), ('fault', 820), ('shipping', 821), ('thriller', 822), ('murderball', 823), ('whiny', 824), ('joe', 825), ('royally', 826), ('neither', 827), ('adult', 828), ('fairly', 829), ('mirror', 830), ('chance', 831), ('post', 832), ('biased', 833), ('sure', 834), ('accompaniment', 835), ('mcmurtry', 836), ('tooo', 837), ('sometimes', 838), ('sequels', 839), ('cleaning', 840), ('wussies', 841), ('amazingly', 842), ('picture', 843), ('job', 844), ('lord', 845), ('mentioned', 846), ('dementors', 847), ('free', 848), ('terrible', 849), ('ew', 850), ('knowing', 851), ('eye', 852), ('refusing', 853), ('homophobes', 854), ('sexual', 855), ('last', 856), ('robe', 857), ('friggin', 858), ('disruption', 859), ('livejournal', 860), ('spy', 861), ('writing', 862), ('version', 863), ('passion', 864), ('asks', 865), ('period', 866), ('decent', 867), ('today', 868), ('bentlys', 869), ('sivullinen', 870), ('funny', 871), ('lit', 872), ('lazy', 873), ('dvd', 874), ('loathed', 875), ('sentry', 876), ('brilliant', 877), ('harry', 878), ('bitter', 879), ('project', 880), ('rides', 881), ('silly', 882), ('christain', 883), ('day', 884), ('decided', 885), ('hopefully', 886), ('pegg', 887), ('action', 888), ('hammy', 889), ('thoughts', 890), ('success', 891), ('huh', 892), ('dart', 893), ('movie', 894), ('figured', 895), ('folk', 896), ('talks', 897), ('lets', 898), ('feeling', 899), ('semester', 900), ('spite', 901), ('dedicated', 902), ('better', 903), ('emily', 904), ('cow', 905), ('however', 906), ('jackson', 907), ('illustrated', 908), ('joke', 909), ('slap', 910), ('fallon', 911), ('park', 912), ('packs', 913), ('quaintly', 914), ('life', 915), ('x', 916), ('forgotten', 917), ('spec', 918), ('asking', 919), ('shraddha', 920), ('kelsie', 921), ('adorable', 922), ('dick', 923), ('facebook', 924), ('christopher', 925), ('concocted', 926), ('health', 927), ('geek', 928), ('watching', 929), ('k', 930), ('dogtown', 931), ('prince', 932), ('sick', 933), ('giving', 934), ('v', 935), ('said', 936), ('heath', 937), ('claiming', 938), ('mention', 939), ('b', 940), ('blogbacklinksnippet', 941), ('whistles', 942), ('mang', 943), ('games', 944), ('lunch', 945), ('otters', 946), ('animated', 947), ('fat', 948), ('rather', 949), ('enough', 950), ('rickards', 951), ('tied', 952), ('wow', 953), ('outside', 954), ('coherent', 955), ('study', 956), ('homosexuality', 957), ('moralistic', 958), ('bless', 959), ('war', 960), ('lapse', 961), ('diversity', 962), ('go', 963), ('precious', 964), ('lives', 965), ('knew', 966), ('empty', 967), ('house', 968), ('lower', 969), ('problem', 970), ('shut', 971), ('along', 972), ('asleep', 973), ('delicious', 974), ('robbed', 975), ('chessboard', 976), ('decline', 977), ('stayed', 978), ('adore', 979), ('others', 980), ('springer', 981), ('packed', 982), ('john', 983), ('mindless', 984), ('potterholic', 985), ('real', 986), ('respect', 987), ('exquisite', 988), ('seen', 989), ('azkaban', 990), ('whatever', 991), ('deals', 992), ('guys', 993), ('gotta', 994), ('pocket', 995), ('reference', 996), ('told', 997), ('completely', 998), ('demons', 999), ('ike', 1000), ('overslept', 1001), ('die', 1002), ('waaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', 1003), ('hating', 1004), ('boyy', 1005), ('cinema', 1006), ('picky', 1007), ('effects', 1008), ('relic', 1009), ('ago', 1010), ('true', 1011), ('craze', 1012), ('imo', 1013), ('christmas', 1014), ('comparrison', 1015), ('total', 1016), ('super', 1017), ('article', 1018), ('hermione', 1019), ('cocktail', 1020), ('ap', 1021), ('broom', 1022), ('word', 1023), ('garrett', 1024), ('meeting', 1025), ('officially', 1026), ('dumbest', 1027), ('rocked', 1028), ('backdrop', 1029), ('admired', 1030), ('smoking', 1031), ('choice', 1032), ('adversity', 1033), ('pretty', 1034), ('disney', 1035), ('shopping', 1036), ('honor', 1037), ('awesomely', 1038), ('titus', 1039), ('immediately', 1040), ('malaguena', 1041), ('dynamite', 1042), ('release', 1043), ('boycott', 1044), ('bikes', 1045), ('page', 1046), ('idiot', 1047), ('secrets', 1048), ('hype', 1049), ('began', 1050), ('good', 1051), ('credit', 1052), ('burnt', 1053), ('work', 1054), ('loves', 1055), ('comprehend', 1056), ('inaccurate', 1057), ('profound', 1058), ('coz', 1059), ('account', 1060), ('changed', 1061), ('many', 1062), ('cowboy', 1063), ('entitled', 1064), ('abrams', 1065), ('ball', 1066), ('likes', 1067), ('soo', 1068), ('sort', 1069), ('learn', 1070), ('come', 1071), ('ism', 1072), ('firstly', 1073), ('whos', 1074), ('basically', 1075), ('russotti', 1076), ('dad', 1077), ('heresies', 1078), ('hate', 1079), ('thursday', 1080), ('please', 1081), ('example', 1082), ('various', 1083), ('sometime', 1084), ('speaker', 1085), ('books', 1086), ('fr', 1087), ('working', 1088), ('jamaica', 1089), ('minutes', 1090), ('found', 1091), ('sports', 1092), ('shipmates', 1093), ('indoctrinate', 1094), ('mcgarther', 1095), ('formed', 1096), ('lotr', 1097), ('soooooo', 1098), ('race', 1099), ('together', 1100), ('mindedness', 1101), ('ruining', 1102), ('answers', 1103), ('useless', 1104), ('excited', 1105), ('nice', 1106), ('power', 1107), ('knight', 1108), ('best', 1109), ('portuguese', 1110), ('thats', 1111), ('napoleon', 1112), ('kill', 1113), ('arse', 1114), ('al', 1115), ('contains', 1116), ('bridget', 1117), ('light', 1118), ('anne', 1119), ('kaka', 1120), ('standpoint', 1121), ('sorry', 1122), ('gl', 1123), ('television', 1124), ('tea', 1125), ('shit', 1126), ('cool', 1127), ('teaches', 1128), ('ignore', 1129), ('enjoyed', 1130), ('marvel', 1131), ('pc', 1132), ('react', 1133), ('rare', 1134), ('much', 1135), ('cousins', 1136), ('damn', 1137), ('eoin', 1138), ('acceptable', 1139), ('spontaneously', 1140), ('finished', 1141), ('ian', 1142), ('man', 1143), ('crazy', 1144), ('english', 1145), ('writer', 1146), ('imagine', 1147), ('sucky', 1148), ('weekends', 1149), ('sold', 1150), ('seymour', 1151), ('jokes', 1152), ('dissapointed', 1153), ('spine', 1154), ('sent', 1155), ('thanks', 1156), ('funniest', 1157), ('lucky', 1158), ('screening', 1159), ('obviously', 1160), ('fanfic', 1161), ('narnia', 1162), ('interview', 1163), ('say', 1164), ('combonation', 1165), ('always', 1166), ('issues', 1167), ('tournament', 1168), ('hyped', 1169), ('west', 1170), ('take', 1171), ('n', 1172), ('editor', 1173), ('ten', 1174), ('explore', 1175), ('went', 1176), ('rps', 1177), ('media', 1178), ('energy', 1179), ('costume', 1180), ('candy', 1181), ('radcliffe', 1182), ('interest', 1183), ('finale', 1184), ('joiners', 1185), ('least', 1186), ('josie', 1187), ('jessica', 1188), ('poem', 1189), ('soon', 1190), ('vito', 1191), ('friends', 1192), ('open', 1193), ('juicy', 1194), ('extremely', 1195), ('luck', 1196), ('emo', 1197), ('therefor', 1198), ('stories', 1199), ('wish', 1200), ('making', 1201), ('anything', 1202), ('either', 1203), ('happen', 1204), ('manga', 1205), ('begin', 1206), ('worse', 1207), ('evilpinkmunky', 1208), ('whole', 1209), ('cussler', 1210), ('normal', 1211), ('overlooking', 1212), ('also', 1213), ('special', 1214), ('critics', 1215), ('motherfuckers', 1216), ('spells', 1217), ('two', 1218), ('packaging', 1219), ('show', 1220), ('actual', 1221), ('weekend', 1222), ('play', 1223), ('still', 1224), ('rereading', 1225), ('shame', 1226), ('spin', 1227), ('listen', 1228), ('haha', 1229), ('dork', 1230), ('school', 1231), ('mckellen', 1232), ('simply', 1233), ('benefit', 1234), ('ask', 1235), ('magic', 1236), ('cos', 1237), ('different', 1238), ('supper', 1239), ('wide', 1240), ('afraid', 1241), ('plays', 1242), ('later', 1243), ('black', 1244), ('laura', 1245), ('person', 1246), ('kirsten', 1247), ('actor', 1248), ('dvds', 1249), ('spanish', 1250), ('twist', 1251), ('johnny', 1252), ('online', 1253), ('onto', 1254), ('although', 1255), ('texts', 1256), ('jame', 1257), ('board', 1258), ('song', 1259), ('felicia', 1260), ('allegedly', 1261), ('schools', 1262), ('wacked', 1263), ('mood', 1264), ('criticizers', 1265), ('sean', 1266), ('tun', 1267), ('sunday', 1268), ('category', 1269), ('simmons', 1270), ('colourfully', 1271), ('million', 1272), ('faked', 1273), ('religion', 1274), ('head', 1275), ('angels', 1276), ('aniwae', 1277), ('pull', 1278), ('noises', 1279), ('rofls', 1280), ('angel', 1281), ('hookup', 1282), ('predictable', 1283), ('stone', 1284), ('equal', 1285), ('heartbreaking', 1286), ('fact', 1287), ('classic', 1288), ('sexy', 1289), ('casanova', 1290), ('gasp', 1291), ('could', 1292), ('budget', 1293), ('visually', 1294), ('attraction', 1295), ('pirated', 1296), ('done', 1297), ('local', 1298), ('piece', 1299), ('friday', 1300), ('think', 1301), ('erm', 1302), ('ideas', 1303), ('freagin', 1304), ('apparently', 1305), ('crack', 1306), ('news', 1307), ('sucked', 1308), ('white', 1309), ('explains', 1310), ('five', 1311), ('subtitles', 1312), ('new', 1313), ('ass', 1314), ('agreed', 1315), ('undercover', 1316), ('omg', 1317), ('keep', 1318), ('happy', 1319), ('costumes', 1320), ('shattered', 1321), ('dumbass', 1322), ('featured', 1323), ('davinci', 1324), ('beat', 1325), ('oscar', 1326), ('aimee', 1327), ('knows', 1328), ('hold', 1329), ('sam', 1330), ('section', 1331), ('honestly', 1332), ('clothed', 1333), ('run', 1334), ('form', 1335), ('eek', 1336), ('fyi', 1337), ('dinner', 1338), ('movies', 1339), ('ashamed', 1340), ('possible', 1341), ('forgot', 1342), ('asshole', 1343), ('backtory', 1344), ('hates', 1345), ('professors', 1346), ('group', 1347), ('j', 1348), ('pale', 1349), ('story', 1350), ('explosions', 1351), ('incredibly', 1352), ('requim', 1353), ('pretending', 1354), ('wiccans', 1355), ('gift', 1356), ('laughed', 1357), ('wins', 1358), ('roommate', 1359), ('possum', 1360), ('first', 1361), ('yeah', 1362), ('paul', 1363), ('dance', 1364), ('bitch', 1365), ('bangs', 1366), ('events', 1367), ('wesley', 1368), ('jenn', 1369), ('hard', 1370), ('lynn', 1371), ('leder', 1372), ('frenzied', 1373), ('phone', 1374), ('comments', 1375), ('rented', 1376), ('besides', 1377), ('posts', 1378), ('hero', 1379), ('rolled', 1380), ('young', 1381), ('lends', 1382), ('clarksville', 1383), ('tc', 1384), ('condeming', 1385), ('mean', 1386), ('yip', 1387), ('fer', 1388), ('second', 1389), ('hahaha', 1390), ('world', 1391), ('criticized', 1392), ('may', 1393), ('kudos', 1394), ('differently', 1395), ('larry', 1396), ('awkward', 1397), ('machine', 1398), ('changes', 1399), ('halloween', 1400), ('bogus', 1401), ('fill', 1402), ('loser', 1403), ('association', 1404), ('novel', 1405), ('extent', 1406), ('turner', 1407), ('end', 1408), ('muahahaahahah', 1409), ('songs', 1410), ('orig', 1411), ('guy', 1412), ('excellent', 1413), ('exploitation', 1414), ('emma', 1415), ('talked', 1416), ('combining', 1417), ('capote', 1418), ('tells', 1419), ('unpredictable', 1420), ('like', 1421), ('genre', 1422), ('picnic', 1423), ('jake', 1424), ('memoirs', 1425), ('bullshit', 1426), ('task', 1427), ('harrison', 1428), ('heart', 1429), ('independent', 1430), ('addition', 1431), ('score', 1432), ('durno', 1433), ('hours', 1434), ('latest', 1435), ('ban', 1436), ('chronicles', 1437), ('count', 1438), ('vintage', 1439), ('nacho', 1440), ('kat', 1441), ('phoenix', 1442), ('keeps', 1443), ('style', 1444), ('marisa', 1445), ('part', 1446), ('eyes', 1447), ('got', 1448), ('win', 1449), ('scientology', 1450), ('considered', 1451), ('brown', 1452), ('disappointing', 1453), ('pup', 1454), ('rode', 1455), ('finals', 1456), ('intense', 1457), ('half', 1458), ('mostly', 1459), ('playing', 1460), ('hour', 1461), ('hilarious', 1462), ('bachelor', 1463), ('kelsey', 1464), ('table', 1465), ('cried', 1466), ('meat', 1467), ('slash', 1468), ('rv', 1469), ('mcphee', 1470), ('room', 1471), ('state', 1472), ('hall', 1473), ('sky', 1474), ('jail', 1475), ('racism', 1476), ('following', 1477), ('crap', 1478), ('close', 1479), ('lynne', 1480), ('apologized', 1481), ('silent', 1482), ('used', 1483), ('involving', 1484), ('hell', 1485), ('heavy', 1486), ('figures', 1487), ('series', 1488), ('thinks', 1489), ('legacy', 1490), ('search', 1491), ('coming', 1492), ('intrigued', 1493), ('seeing', 1494), ('mother', 1495), ('deep', 1496), ('deluded', 1497), ('try', 1498), ('industry', 1499), ('positions', 1500), ('sit', 1501), ('philosopher', 1502), ('timings', 1503), ('calls', 1504), ('remix', 1505), ('walk', 1506), ('blood', 1507), ('student', 1508), ('next', 1509), ('except', 1510), ('partyin', 1511), ('hogwash', 1512), ('yesterday', 1513), ('reader', 1514), ('biggie', 1515), ('joy', 1516), ('jesus', 1517), ('impressive', 1518), ('station', 1519), ('postponed', 1520), ('phillip', 1521), ('intellectual', 1522), ('banning', 1523), ('ok', 1524), ('scene', 1525), ('val', 1526), ('chinese', 1527), ('talkin', 1528), ('included', 1529), ('depth', 1530), ('generation', 1531), ('longer', 1532), ('rid', 1533), ('cute', 1534), ('threw', 1535), ('question', 1536), ('thousand', 1537), ('seemed', 1538), ('showing', 1539), ('ive', 1540), ('hear', 1541), ('enjoyment', 1542), ('fall', 1543), ('around', 1544), ('eat', 1545), ('astonishingly', 1546), ('cake', 1547), ('travel', 1548), ('barnyard', 1549), ('sucking', 1550), ('degraw', 1551), ('winter', 1552), ('prediction', 1553), ('characterization', 1554), ('panties', 1555), ('almost', 1556), ('convo', 1557), ('libre', 1558), ('supposed', 1559), ('wondered', 1560), ('recently', 1561), ('protests', 1562), ('titanic', 1563), ('tho', 1564), ('ya', 1565), ('inside', 1566), ('drain', 1567), ('wrong', 1568), ('loudest', 1569), ('immensely', 1570), ('humor', 1571), ('listens', 1572), ('involve', 1573), ('debates', 1574), ('derek', 1575), ('ended', 1576), ('whatev', 1577), ('consumed', 1578), ('weeeellllllll', 1579), ('weiners', 1580), ('find', 1581), ('start', 1582), ('giants', 1583), ('called', 1584), ('lubb', 1585), ('finish', 1586), ('delayed', 1587), ('vic', 1588), ('murdered', 1589), ('food', 1590), ('mission', 1591), ('draco', 1592), ('lie', 1593), ('chamber', 1594), ('clubbin', 1595), ('way', 1596), ('cringe', 1597), ('despise', 1598), ('ridiculous', 1599), ('obnoxious', 1600), ('infuser', 1601), ('supporting', 1602), ('hairy', 1603), ('oversimplifying', 1604), ('shop', 1605), ('proud', 1606), ('matters', 1607), ('places', 1608), ('stinks', 1609), ('haunt', 1610), ('sister', 1611), ('danielle', 1612), ('xd', 1613), ('rosie', 1614), ('scent', 1615), ('inspired', 1616), ('read', 1617), ('incredible', 1618), ('related', 1619), ('dress', 1620), ('japenese', 1621), ('write', 1622), ('perhaps', 1623), ('messy', 1624), ('pudding', 1625), ('tautou', 1626), ('funner', 1627), ('dream', 1628), ('brooke', 1629), ('whether', 1630), ('awards', 1631), ('conversations', 1632), ('freaking', 1633), ('adaptation', 1634), ('simon', 1635), ('okay', 1636), ('idiots', 1637), ('mrs', 1638), ('sum', 1639), ('master', 1640), ('shittiest', 1641), ('field', 1642), ('inherently', 1643), ('soooo', 1644), ('future', 1645), ('something', 1646), ('radio', 1647), ('spend', 1648), ('didnt', 1649), ('unauthorized', 1650), ('reviews', 1651), ('equally', 1652), ('mary', 1653), ('arenas', 1654), ('dies', 1655), ('made', 1656), ('director', 1657), ('saw', 1658), ('attached', 1659), ('pic', 1660), ('top', 1661), ('ps', 1662), ('ultimatly', 1663), ('bbm', 1664), ('opinion', 1665), ('tired', 1666), ('staying', 1667), ('canceled', 1668), ('poseidon', 1669), ('quiz', 1670), ('equus', 1671), ('yea', 1672), ('background', 1673), ('freshman', 1674), ('course', 1675), ('surprisingly', 1676), ('absurd', 1677), ('speaking', 1678), ('iron', 1679), ('nasy', 1680), ('turn', 1681), ('snowing', 1682), ('perfect', 1683), ('died', 1684), ('crystal', 1685), ('hardcore', 1686), ('finshed', 1687), ('moments', 1688), ('pirates', 1689), ('death', 1690), ('diana', 1691), ('pop', 1692), ('dramatic', 1693), ('tickets', 1694), ('icons', 1695), ('vs', 1696), ('insane', 1697), ('trailers', 1698), ('spectacularly', 1699), ('tried', 1700), ('nanny', 1701), ('feast', 1702), ('brokeback', 1703), ('richard', 1704), ('get', 1705), ('fit', 1706), ('mpreg', 1707), ('monthly', 1708), ('desperate', 1709), ('telling', 1710), ('pages', 1711), ('twice', 1712), ('rice', 1713), ('conversation', 1714), ('decides', 1715), ('effort', 1716), ('tonite', 1717), ('theological', 1718), ('rant', 1719), ('frodo', 1720), ('oceans', 1721), ('anatomy', 1722), ('note', 1723), ('track', 1724), ('letter', 1725), ('gayness', 1726), ('portugal', 1727), ('reminded', 1728), ('cucumber', 1729), ('joan', 1730), ('three', 1731), ('street', 1732), ('reason', 1733), ('fears', 1734), ('darkness', 1735), ('offensive', 1736), ('popular', 1737), ('realize', 1738), ('virgin', 1739), ('rocks', 1740), ('soul', 1741), ('lama', 1742), ('friendships', 1743), ('regardless', 1744), ('escapades', 1745), ('anus', 1746), ('heather', 1747), ('executed', 1748), ('hey', 1749), ('full', 1750), ('past', 1751), ('vacation', 1752), ('plausible', 1753), ('apart', 1754), ('decide', 1755), ('one', 1756), ('glitz', 1757), ('topic', 1758), ('colony', 1759), ('lake', 1760), ('dogfucking', 1761), ('campaign', 1762), ('match', 1763), ('requested', 1764), ('people', 1765), ('fandom', 1766), ('anyway', 1767), ('gun', 1768), ('im', 1769), ('immortal', 1770), ('week', 1771), ('back', 1772), ('near', 1773), ('side', 1774), ('gyllenhaal', 1775), ('broke', 1776), ('fits', 1777), ('plain', 1778), ('body', 1779), ('predictability', 1780), ('highly', 1781), ('decomposing', 1782), ('glad', 1783), ('surprised', 1784), ('going', 1785), ('chunnel', 1786), ('makes', 1787), ('douche', 1788), ('tragically', 1789), ('actors', 1790), ('julia', 1791), ('center', 1792), ('boring', 1793), ('complaints', 1794), ('mocking', 1795), ('bro', 1796), ('gays', 1797), ('blasphying', 1798), ('dislike', 1799), ('families', 1800), ('st', 1801), ('superman', 1802), ('overall', 1803), ('explaination', 1804), ('grand', 1805), ('chronological', 1806), ('worlds', 1807), ('pressing', 1808), ('folows', 1809), ('younger', 1810), ('ootp', 1811), ('hands', 1812), ('shes', 1813), ('ballz', 1814), ('haunted', 1815), ('tomorrow', 1816), ('getting', 1817), ('believe', 1818), ('sucks', 1819), ('shaped', 1820), ('four', 1821), ('conclusion', 1822), ('trip', 1823), ('fire', 1824), ('idea', 1825), ('malfoy', 1826), ('year', 1827), ('involved', 1828), ('becoming', 1829), ('defensive', 1830), ('share', 1831), ('eragon', 1832), ('strip', 1833), ('wondering', 1834), ('talk', 1835), ('moives', 1836), ('cowboys', 1837), ('book', 1838), ('phrase', 1839), ('men', 1840), ('months', 1841), ('beyond', 1842), ('hope', 1843), ('explain', 1844), ('specifically', 1845), ('artemis', 1846), ('ron', 1847), ('frog', 1848), ('devil', 1849), ('potter', 1850), ('really', 1851), ('saturday', 1852), ('fanfiction', 1853), ('tennis', 1854), ('fucking', 1855), ('thing', 1856), ('otp', 1857), ('point', 1858), ('south', 1859), ('england', 1860), ('wiccanism', 1861), ('heteronormativity', 1862), ('wicca', 1863), ('hated', 1864), ('evil', 1865), ('short', 1866), ('beach', 1867), ('gosh', 1868), ('hoot', 1869), ('deal', 1870), ('flick', 1871), ('ruined', 1872), ('kate', 1873), ('awesome', 1874), ('barry', 1875), ('crusade', 1876), ('suicides', 1877), ('melbourne', 1878), ('fair', 1879), ('tell', 1880), ('awful', 1881), ('stuff', 1882), ('gadgets', 1883), ('bad', 1884), ('cheapened', 1885), ('fabulous', 1886), ('goth', 1887), ('oddly', 1888), ('money', 1889), ('sitting', 1890), ('wranglers', 1891), ('hello', 1892), ('laid', 1893), ('blanks', 1894), ('ultimate', 1895), ('interested', 1896), ('blogbacklinktitle', 1897), ('hoover', 1898), ('tiny', 1899), ('color', 1900), ('even', 1901), ('heard', 1902), ('saying', 1903), ('clickfive', 1904), ('expo', 1905), ('crash', 1906), ('judgement', 1907), ('whimpering', 1908), ('drove', 1909), ('film', 1910), ('worst', 1911), ('kiss', 1912), ('politics', 1913), ('ah', 1914), ('ripping', 1915), ('tome', 1916), ('buy', 1917), ('brother', 1918), ('look', 1919), ('thesis', 1920), ('looks', 1921), ('suppose', 1922), ('vault', 1923), ('stupidest', 1924), ('hedge', 1925), ('suspenseful', 1926), ('poorly', 1927), ('libraries', 1928), ('wholesome', 1929), ('little', 1930), ('rings', 1931), ('letting', 1932), ('finally', 1933), ('google', 1934), ('outshines', 1935), ('rock', 1936), ('optimus', 1937), ('entire', 1938), ('infiltrate', 1939), ('slow', 1940), ('tragic', 1941), ('earrings', 1942), ('office', 1943), ('psychology', 1944), ('would', 1945), ('warns', 1946), ('subjects', 1947), ('franchise', 1948), ('horrible', 1949), ('targeted', 1950), ('christianity', 1951), ('jon', 1952), ('girls', 1953), ('definitely', 1954), ('childishly', 1955), ('het', 1956), ('walks', 1957), ('exception', 1958), ('sue', 1959), ('culture', 1960), ('bet', 1961), ('attractive', 1962), ('picard', 1963), ('exponentially', 1964), ('main', 1965), ('tan', 1966), ('living', 1967), ('selfish', 1968), ('hogwarts', 1969), ('rehearsal', 1970), ('comparsions', 1971), ('basket', 1972), ('class', 1973), ('loved', 1974), ('probable', 1975), ('takes', 1976), ('insanely', 1977), ('amazing', 1978), ('tourist', 1979), ('ending', 1980), ('fic', 1981), ('chick', 1982), ('wanted', 1983), ('mom', 1984), ('awesomest', 1985), ('less', 1986), ('requiem', 1987), ('luau', 1988), ('boycotting', 1989), ('closet', 1990), ('ony', 1991), ('mad', 1992), ('turned', 1993)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_int = {word: i for i, word in enumerate(unique_words, 1)}\n",
    "vocab_to_int.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_inputs_words = []   ## array of review where each review again is an array\n",
    "\n",
    "for review in cleaned_inputs:\n",
    "    cleaned_inputs_words.append(review.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform inputs into array of integers\n",
    "\n",
    "Using vocab_to_int to transform each review to vector of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length 0\n",
      "Max review length 487\n"
     ]
    }
   ],
   "source": [
    "cleaned_inputs_ints = []\n",
    "\n",
    "for review in cleaned_inputs_words:\n",
    "    cleaned_inputs_ints.append([vocab_to_int[word] for word in review])\n",
    "   \n",
    "reviews_lens = Counter([len(x) for x in cleaned_inputs_ints])\n",
    "print('Zero-length {}'.format(reviews_lens[0]))\n",
    "print(\"Max review length {}\".format(max(reviews_lens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating word vectors\n",
    "\n",
    "This step can be done as:\n",
    "1. Define sequence length. (250 in this case)\n",
    "2. Each review shorter then this sequence length will be padded (at the beginning) with zeros\n",
    "3. Each review longer than the sequence length will be shortened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...,  392   66 1910]\n",
      " [   0    0    0 ...,  740  392   66]\n",
      " [   0    0    0 ..., 1974 1703   90]\n",
      " ..., \n",
      " [   0    0    0 ...,  158 1703   90]\n",
      " [   0    0    0 ...,  588  940  329]\n",
      " [   0    0    0 ..., 1756 1874 1350]]\n"
     ]
    }
   ],
   "source": [
    "seq_len = 250\n",
    "\n",
    "# create matrix of size len(leaned_inputs_ints) X seq_len\n",
    "features = np.zeros((len(cleaned_inputs_ints), seq_len), dtype=int)   \n",
    "\n",
    "for i, review in enumerate(cleaned_inputs_ints):\n",
    "    features[i, -len(review):] = np.array(review)[:seq_len]  # last 250 words\n",
    "\n",
    "print(features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and testing parts¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trian shape (5000, 250)\n",
      "X_test shape (1917, 250)\n"
     ]
    }
   ],
   "source": [
    "X_train = features[:5000]\n",
    "y_train = labels[:5000]\n",
    "\n",
    "X_test = features[5000:]\n",
    "y_test = labels[5000:]\n",
    "\n",
    "print('X_train shape {}'.format(X_train.shape))\n",
    "print('X_test shape {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 128  #512 how many nodes LSTM cells will have\n",
    "number_of_layers = 1 # how many RNN layers the network will have\n",
    "batch_size = 50 # how many reviews we feed at onces\n",
    "learning_rate = 0.001 # learning rate\n",
    "number_of_words = len(vocab_to_int) + 1 #how many unique words do we have in vocab (+1  is used for 0 - padding)\n",
    "dropout_rate = 0.8 \n",
    "embed_size = 300 #how long our word embedings will be\n",
    "epochs = 5 # how many epochs do we use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #Clean the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define placeholders¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "targets = tf.placeholder(tf.int32, [None, None], name='targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define embeding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedings = tf.Variable(tf.random_uniform((number_of_words, embed_size), -1, 1))\n",
    "embed = tf.nn.embedding_lookup(word_embedings, inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hidden layer and Dynamic RNN¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer = tf.contrib.rnn.BasicLSTMCell(hidden_layer_size)\n",
    "hidden_layer = tf.contrib.rnn.DropoutWrapper(hidden_layer, dropout_rate)\n",
    "\n",
    "cell = tf.contrib.rnn.MultiRNNCell([hidden_layer]*number_of_layers)\n",
    "init_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(cell, embed, initial_state=init_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the prediction for each review\n",
    "From the last step of our network we get output and use it as a prediction. Than we use that result and compare it with real sentiment for that review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.layers.dense(outputs[:, -1], 1, activation=tf.sigmoid)\n",
    "cost = tf.losses.mean_squared_error(targets, prediction)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "currect_pred = tf.equal(tf.cast(tf.round(prediction), tf.int32), targets)\n",
    "accuracy = tf.reduce_mean(tf.cast(currect_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5  | Current loss: 0.04459916427731514  | Training accuracy: 94.4600\n",
      "Epoch: 1/5  | Current loss: 0.004780552815645933  | Training accuracy: 99.4600\n",
      "Epoch: 2/5  | Current loss: 0.002057114150375128  | Training accuracy: 99.7600\n",
      "Epoch: 3/5  | Current loss: 0.001287223887629807  | Training accuracy: 99.8600\n",
      "Epoch: 4/5  | Current loss: 0.0008348678820766509  | Training accuracy: 99.9200\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    training_accurcy = []\n",
    "    ii = 0\n",
    "    epoch_loss = []\n",
    "    while ii + batch_size <= len(X_train):\n",
    "        X_batch = X_train[ii:ii+batch_size]\n",
    "        y_batch = y_train[ii:ii+batch_size].reshape(-1, 1)\n",
    "        \n",
    "        a, o, _ = session.run([accuracy, cost, optimizer], feed_dict={inputs:X_batch, targets:y_batch})\n",
    "\n",
    "        training_accurcy.append(a)\n",
    "        epoch_loss.append(o)\n",
    "        ii += batch_size\n",
    "    print('Epoch: {}/{}'.format(i, epochs), ' | Current loss: {}'.format(np.mean(epoch_loss)),\n",
    "          ' | Training accuracy: {:.4f}'.format(np.mean(training_accurcy)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_accuracy = []\n",
    "\n",
    "ii = 0\n",
    "while ii + batch_size <= len(X_test):\n",
    "    X_batch = X_test[ii:ii+batch_size]\n",
    "    y_batch = y_test[ii:ii+batch_size].reshape(-1, 1)\n",
    "\n",
    "    a = session.run([accuracy], feed_dict={inputs:X_batch, targets:y_batch})\n",
    "    \n",
    "    test_accuracy.append(a)\n",
    "    ii += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 99.0526%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy is {:.4f}%\".format(np.mean(test_accuracy)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Happy ML!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
